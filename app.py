# -*- coding: utf-8 -*-
"""cv_app

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ScGYj1nnsUsxCBPlDU1uS7LSETepacen
"""

from pathlib import Path

import streamlit as st
from PIL import Image


# --- PATH SETTINGS ---
current_dir = Path(__file__).parent if "__file__" in locals() else Path.cwd()
css_file = current_dir / "styles" / "main.css"
resume_file = current_dir / "assets" / "Deepak_Kaura_Resume_2023.pdf"
profile_pic = current_dir / "assets" / "Formal Photo.png"


# --- GENERAL SETTINGS ---
PAGE_TITLE = "Digital CV | Deepak Kaura"
PAGE_ICON = ":wave:"
NAME = "Deepak Kaura"
DESCRIPTION = """
As an driven Data Science enthusiast with 11 months of hands-on experience, the goal is to leverage existing skills and knowledge to effectively contribute to your organization.
Possessing a strong background in Python, there is expertise in various essential areas of Data Science, encompassing Data Cleaning, Feature Engineering,
Data Exploration, Visualization, Predictive Analytics and Machine Learning. Proficiency in implementing diverse algorithms, including Linear Regression, Logistic Regression,
Random Forest and Decision Tree, is coupled with the ability to deploy models using Streamlit.
The aim is to be a highly productive employee capable of driving valuable insights, thereby contributing to the growth of the organization.
"""
EMAIL = "kauradeepak@gmail.com"
SOCIAL_MEDIA = {
    "YouTube": "https://www.youtube.com/channel/UCgIenOB7b3aEuo4e6Nv8BZQ",
    "LinkedIn": "www.linkedin.com/in/deepak-kaura-66a903162",
    "GitHub": "https://github.com/deepak7642",
    "Kaggle": "https://www.kaggle.com/deepakkaura",
}
PROJECTS = {
    "üèÜ Fiverr : End-to-End Project includes Deployment -  Find a good fit algorithm which will have Potential to Predict Spammers.": "https://www.kaggle.com/code/deepakkaura/fiverr-end-to-end-project-includes-deployment",
    "üèÜ Audit Risk : ML will help !!! - The goal of the dataset is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors": "https://www.kaggle.com/code/deepakkaura/audit-risk-ml-will-help",
    "üèÜ Lead Score : PyCaret Story Begins - Solving real world problem with PyCaret": "https://www.kaggle.com/code/deepakkaura/lead-score-pycaret-story-begins",
    "üèÜ The Champions League Final: A Tale of Two Cities - To select the best team for the Finals": "https://www.kaggle.com/code/deepakkaura/the-champions-league-final-a-tale-of-two-cities/notebook",
}


st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON)


# --- LOAD CSS, PDF & PROFIL PIC ---
with open(css_file) as f:
    st.markdown("<style>{}</style>".format(f.read()), unsafe_allow_html=True)
with open(resume_file, "rb") as pdf_file:
    PDFbyte = pdf_file.read()
profile_pic = Image.open(profile_pic)


# --- HERO SECTION ---
col1, col2 = st.columns(2, gap="small")
with col1:
    st.image(profile_pic, width=230)

with col2:
    st.title(NAME)
    st.write(DESCRIPTION)
    st.download_button(
        label=" üìÑ Download Resume",
        data=PDFbyte,
        file_name=resume_file.name,
        mime="application/octet-stream",
    )
    st.write("üì´", EMAIL)


# --- SOCIAL LINKS ---
st.write('\n')
cols = st.columns(len(SOCIAL_MEDIA))
for index, (platform, link) in enumerate(SOCIAL_MEDIA.items()):
    cols[index].write(f"[{platform}]({link})")


# --- QUALIFICATIONS & CERTIFICATIONS ---
st.write('\n')
st.subheader("Qulifications & Certifications")
st.write(
    """
- ‚úîÔ∏è MBAFP, International College Of Financial Planning affiliated with Mysore University
- ‚úîÔ∏è Integrated Program in Business Analytics (IPBA) By IIM Indore with Jigsaw Academy (Mar, 21 - Jan, 22)
- ‚úîÔ∏è Advanced Certification in Applied Data Science, Machine Learning & IoT By E&ICT Academy, IIT Guwahati (recently over)
"""
)


# --- SKILLS ---
st.write('\n')
st.subheader("Hard Skills")
st.write(
    """
- üìí IDE: Google Colab, Kaggle
- üë©‚Äçüíª Programming: Python (Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-learn)
- üìä Data Visulization: MS Excel, Tableau (learning stage)
- üìö Modeling: Linear Regression, Logistic Regression, Decition Trees and Random Forest
- üåê Deployment: Streamlit
- üóÑÔ∏è Databases: MS-SQL (learning stage)
"""
)


# --- WORK HISTORY ---
st.write('\n')
st.subheader("Work History")
st.write("---")

# --- INTERNSHIP/JOB 1
st.write("üöß", "**ML Engineer (ML Team Leader) | Rework AI**")
st.write("Mar 2023 - Present")
st.write(
    """
- Building robust HR solutions that automate time-consuming tasks and improve the efficiency of the hiring process : -
- ‚ñ∫ Automated Job Descriptions - Generating job description with the help of open-source GPT models to create high-quality job descriptions in minutes.
- ‚ñ∫ Matching Resumes with Job Description - Using Natural Language Processing (NLP) techniques, and developed advanced algorithms that effectively match resumes with job descriptions.
"""
)

# --- INTERNSHIP 2
st.write('\n')
st.write("üöß", "**Data Analyst Engineer | Resolute.AI**")
st.write("Apr 2022 - Jul 2022")
st.write(
    """
- ‚ñ∫ Primary tasks involve predictive analytics on various industry use cases and develop predictive models to analyze data patterns, trends, and relationships
- ‚ñ∫ Secondary tasks revolve around building a UI with Streamlit to deploy exploratory data analysis using Altair and Plotly libraries.
"""
)

# --- INTERNSHIP 3
st.write('\n')
st.write("üöß", "**Machine Learning | A2J Technology**")
st.write("Oct 2021 - Jan 2022")
st.write(
    """
- ‚ñ∫ The tasks involve data cleaning, cashflow prediction using LSTM with hyper-tuning, and implementing various machine learning algorithms such as Logistic Regression, Random Forest, and Decision Tree
- ‚ñ∫ The aim is to optimize the models and determine the most effective algorithm for the given dataset.
"""
)

# --- INTERNSHIP 4
st.write('\n')
st.write("üöß", "**Data Science & Business Analytics | The Sparks Foundation**")
st.write("Jan 2021 ‚Äì Feb 2021")
st.write(
    """
- ‚ñ∫ The tasks revolve around conducting exploratory data analysis and implementing machine learning techniques. The steps include EDA, data preprocessing, algorithm selection, model training, evaluation, and optimization.
- For more details : - https://github.com/deepak7642/deepakkaura-TSF-Internship-GRIPJAN2021-
"""
)

# --- Projects & Accomplishments ---
st.write('\n')
st.subheader("Projects & Accomplishments")
st.write("---")
for project, link in PROJECTS.items():
    st.write(f"[{project}]({link})")